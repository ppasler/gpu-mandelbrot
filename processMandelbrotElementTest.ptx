//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Sep  5 06:40:32 2014 (1409892032)
// Cuda compilation tools, release 6.5, V6.5.19
//

.version 4.1
.target sm_20
.address_size 64


.visible .func  (.param .b64 func_retval0) _Z20calculateGlobalIndexv(

)
{
	.reg .s32 	%r<11>;
	.reg .s64 	%rd<4>;


	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ctaid.y;
	mov.u32 	%r3, %nctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	cvt.u64.u32	%rd1, %r8;
	mov.u32 	%r9, %ntid.y;
	mul.lo.s32 	%r10, %r9, %r6;
	mul.wide.u32 	%rd2, %r10, %r4;
	add.s64 	%rd3, %rd2, %rd1;
	st.param.b64	[func_retval0+0], %rd3;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z12doIterationsddddj(
	.param .b64 _Z12doIterationsddddj_param_0,
	.param .b64 _Z12doIterationsddddj_param_1,
	.param .b64 _Z12doIterationsddddj_param_2,
	.param .b64 _Z12doIterationsddddj_param_3,
	.param .b32 _Z12doIterationsddddj_param_4
)
{
	.reg .pred 	%p<3>;
	.reg .s32 	%r<7>;
	.reg .f64 	%fd<20>;


	ld.param.f64 	%fd6, [_Z12doIterationsddddj_param_0];
	ld.param.f64 	%fd7, [_Z12doIterationsddddj_param_1];
	ld.param.f64 	%fd8, [_Z12doIterationsddddj_param_2];
	ld.param.f64 	%fd9, [_Z12doIterationsddddj_param_3];
	ld.param.u32 	%r4, [_Z12doIterationsddddj_param_4];
	add.f64 	%fd1, %fd9, %fd9;
	mov.u32 	%r6, 0;
	mov.f64 	%fd18, %fd7;
	mov.f64 	%fd19, %fd6;

BB1_1:
	mov.f64 	%fd3, %fd19;
	mov.f64 	%fd2, %fd18;
	mul.f64 	%fd10, %fd2, %fd2;
	fma.rn.f64 	%fd11, %fd3, %fd3, %fd10;
	setp.gtu.f64	%p1, %fd11, 0d4010000000000000;
	@%p1 bra 	BB1_3;

	add.s32 	%r6, %r6, 1;
	mul.f64 	%fd12, %fd3, %fd8;
	mul.f64 	%fd13, %fd12, %fd3;
	mul.f64 	%fd14, %fd2, %fd9;
	mul.f64 	%fd15, %fd14, %fd2;
	sub.f64 	%fd16, %fd13, %fd15;
	add.f64 	%fd4, %fd16, %fd6;
	mul.f64 	%fd17, %fd1, %fd3;
	fma.rn.f64 	%fd5, %fd17, %fd2, %fd7;
	setp.le.u32	%p2, %r6, %r4;
	mov.f64 	%fd18, %fd5;
	mov.f64 	%fd19, %fd4;
	@%p2 bra 	BB1_1;

BB1_3:
	st.param.b32	[func_retval0+0], %r6;
	ret;
}

.visible .entry _Z28processMandelbrotElementTestPdPKdS1_ddjjj(
	.param .u64 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_0,
	.param .u64 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_1,
	.param .u64 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_2,
	.param .f64 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_3,
	.param .f64 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_4,
	.param .u32 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_5,
	.param .u32 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_6,
	.param .u32 _Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_7
)
{
	.reg .pred 	%p<11>;
	.reg .s32 	%r<43>;
	.reg .s64 	%rd<16>;
	.reg .f64 	%fd<77>;


	ld.param.u64 	%rd3, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_0];
	ld.param.u64 	%rd4, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_1];
	ld.param.u64 	%rd5, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_2];
	ld.param.f64 	%fd15, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_3];
	ld.param.f64 	%fd16, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_4];
	ld.param.u32 	%r15, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_5];
	mov.u32 	%r16, %ctaid.x;
	mov.u32 	%r17, %nctaid.x;
	mov.u32 	%r18, %ctaid.y;
	mad.lo.s32 	%r19, %r17, %r18, %r16;
	mov.u32 	%r20, %tid.y;
	mov.u32 	%r21, %ntid.x;
	mov.u32 	%r22, %tid.x;
	mad.lo.s32 	%r23, %r20, %r21, %r22;
	cvt.u64.u32	%rd6, %r23;
	mov.u32 	%r24, %ntid.y;
	mul.lo.s32 	%r25, %r24, %r21;
	mul.wide.u32 	%rd7, %r25, %r19;
	add.s64 	%rd1, %rd7, %rd6;
	ld.param.u32 	%rd8, [_Z28processMandelbrotElementTestPdPKdS1_ddjjj_param_7];
	setp.ge.u64	%p1, %rd1, %rd8;
	@%p1 bra 	BB2_17;

	cvta.to.global.u64 	%rd9, %rd4;
	cvta.to.global.u64 	%rd10, %rd5;
	cvta.to.global.u64 	%rd2, %rd3;
	shl.b64 	%rd11, %rd1, 3;
	add.s64 	%rd12, %rd9, %rd11;
	ld.global.f64 	%fd1, [%rd12];
	add.s64 	%rd13, %rd10, %rd11;
	ld.global.f64 	%fd2, [%rd13];
	add.f64 	%fd3, %fd16, %fd16;
	mov.u32 	%r38, 0;
	mov.f64 	%fd73, %fd2;
	mov.f64 	%fd74, %fd1;

BB2_2:
	mov.f64 	%fd5, %fd74;
	mov.f64 	%fd4, %fd73;
	mul.f64 	%fd17, %fd4, %fd4;
	fma.rn.f64 	%fd18, %fd5, %fd5, %fd17;
	setp.gtu.f64	%p2, %fd18, 0d4010000000000000;
	@%p2 bra 	BB2_4;

	add.s32 	%r38, %r38, 1;
	mul.f64 	%fd19, %fd5, %fd15;
	mul.f64 	%fd20, %fd19, %fd5;
	mul.f64 	%fd21, %fd4, %fd16;
	mul.f64 	%fd22, %fd21, %fd4;
	sub.f64 	%fd23, %fd20, %fd22;
	add.f64 	%fd6, %fd23, %fd1;
	mul.f64 	%fd24, %fd3, %fd5;
	fma.rn.f64 	%fd7, %fd24, %fd4, %fd2;
	setp.le.u32	%p3, %r38, %r15;
	mov.f64 	%fd73, %fd7;
	mov.f64 	%fd74, %fd6;
	@%p3 bra 	BB2_2;

BB2_4:
	add.s32 	%r4, %r38, 1;
	cvt.rn.f64.u32	%fd8, %r4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd8;
	}
	setp.ne.s32	%p4, %r4, 0;
	setp.lt.s32	%p5, %r39, 2146435072;
	and.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB2_10;

	abs.f64 	%fd25, %fd8;
	setp.gtu.f64	%p7, %fd25, 0d7FF0000000000000;
	@%p7 bra 	BB2_9;

	@%p4 bra 	BB2_8;

	mov.f64 	%fd76, 0dFFF0000000000000;
	bra.uni 	BB2_16;

BB2_8:
	mov.f64 	%fd76, 0dFFF8000000000000;
	bra.uni 	BB2_16;

BB2_9:
	add.f64 	%fd76, %fd8, %fd8;
	bra.uni 	BB2_16;

BB2_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd8;
	}
	setp.lt.s32	%p9, %r39, 1048576;
	@%p9 bra 	BB2_12;

	mov.u32 	%r41, -1023;
	bra.uni 	BB2_13;

BB2_12:
	mul.f64 	%fd28, %fd8, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd28;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r40, %temp}, %fd28;
	}
	mov.u32 	%r41, -1077;

BB2_13:
	shr.u32 	%r29, %r39, 20;
	add.s32 	%r42, %r41, %r29;
	and.b32  	%r30, %r39, -2146435073;
	or.b32  	%r31, %r30, 1072693248;
	mov.b64 	%fd75, {%r40, %r31};
	setp.lt.s32	%p10, %r31, 1073127583;
	@%p10 bra 	BB2_15;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd75;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd75;
	}
	add.s32 	%r34, %r33, -1048576;
	mov.b64 	%fd75, {%r32, %r34};
	add.s32 	%r42, %r42, 1;

BB2_15:
	add.f64 	%fd30, %fd75, 0d3FF0000000000000;
	mov.f64 	%fd31, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd29,%fd30;
	// inline asm
	neg.f64 	%fd32, %fd30;
	fma.rn.f64 	%fd33, %fd32, %fd29, %fd31;
	fma.rn.f64 	%fd34, %fd33, %fd33, %fd33;
	fma.rn.f64 	%fd35, %fd34, %fd29, %fd29;
	add.f64 	%fd36, %fd75, 0dBFF0000000000000;
	mul.f64 	%fd37, %fd36, %fd35;
	fma.rn.f64 	%fd38, %fd36, %fd35, %fd37;
	mul.f64 	%fd39, %fd38, %fd38;
	mov.f64 	%fd40, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd41, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd42, %fd41, %fd39, %fd40;
	mov.f64 	%fd43, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd44, %fd42, %fd39, %fd43;
	mov.f64 	%fd45, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd46, %fd44, %fd39, %fd45;
	mov.f64 	%fd47, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd48, %fd46, %fd39, %fd47;
	mov.f64 	%fd49, 0d3F624924923BE72D;
	fma.rn.f64 	%fd50, %fd48, %fd39, %fd49;
	mov.f64 	%fd51, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd52, %fd50, %fd39, %fd51;
	mov.f64 	%fd53, 0d3FB5555555555554;
	fma.rn.f64 	%fd54, %fd52, %fd39, %fd53;
	sub.f64 	%fd55, %fd36, %fd38;
	add.f64 	%fd56, %fd55, %fd55;
	neg.f64 	%fd57, %fd38;
	fma.rn.f64 	%fd58, %fd57, %fd36, %fd56;
	mul.f64 	%fd59, %fd35, %fd58;
	mul.f64 	%fd60, %fd54, %fd39;
	fma.rn.f64 	%fd61, %fd60, %fd38, %fd59;
	xor.b32  	%r35, %r42, -2147483648;
	mov.u32 	%r36, -2147483648;
	mov.u32 	%r37, 1127219200;
	mov.b64 	%fd62, {%r35, %r37};
	mov.b64 	%fd63, {%r36, %r37};
	sub.f64 	%fd64, %fd62, %fd63;
	mov.f64 	%fd65, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd66, %fd64, %fd65, %fd38;
	neg.f64 	%fd67, %fd64;
	fma.rn.f64 	%fd68, %fd67, %fd65, %fd66;
	sub.f64 	%fd69, %fd68, %fd38;
	sub.f64 	%fd70, %fd61, %fd69;
	mov.f64 	%fd71, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd72, %fd64, %fd71, %fd70;
	add.f64 	%fd76, %fd66, %fd72;

BB2_16:
	add.s64 	%rd15, %rd2, %rd11;
	st.global.f64 	[%rd15], %fd76;

BB2_17:
	ret;
}


